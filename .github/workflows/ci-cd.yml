name: GFN Pipeline CI/CD

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  PYTHON_VERSION: "3.11"

jobs:
  lint:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"
          github-token: ${{ github.token }}
      
      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: uv sync --dev
      
      - name: Run Ruff linter
        run: uv run ruff check src/ tests/ infrastructure/
      
      - name: Run Ruff formatter check
        run: uv run ruff format --check src/ tests/ infrastructure/
      
      - name: Run type checking
        run: uv run mypy src/ --ignore-missing-imports
        continue-on-error: true  # Type checking is advisory

  test:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v4
      
      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"
          github-token: ${{ github.token }}
      
      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: uv sync --dev
      
      - name: Run unit tests with coverage
        run: |
          uv run pytest tests/ \
            -v \
            -m "not integration" \
            --cov=src/gfn_pipeline \
            --cov-report=xml \
            --cov-report=term-missing \
            --junitxml=test-results.xml
        env:
          # Mock credentials for unit tests (not used, but prevents import errors)
          GFN_API_KEY: "test_key"
          AWS_ACCESS_KEY_ID: "test"
          AWS_SECRET_ACCESS_KEY: "test"
          AWS_DEFAULT_REGION: "us-east-1"
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: coverage.xml
          fail_ci_if_error: false

  integration-test:
    name: Integration Tests (LocalStack)
    runs-on: ubuntu-latest
    needs: test
    services:
      localstack:
        image: localstack/localstack:3.0
        ports:
          - 4566:4566
        env:
          SERVICES: s3,lambda,sqs,sns,events,stepfunctions,logs,iam
          DEFAULT_REGION: us-east-1
          DOCKER_HOST: unix:///var/run/docker.sock
        options: >-
          --health-cmd "curl -sf http://localhost:4566/_localstack/health"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v4
      
      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"
          github-token: ${{ github.token }}
      
      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: uv sync --dev
      
      - name: Wait for LocalStack to be ready
        run: |
          echo "Waiting for LocalStack..."
          timeout 60 bash -c 'until curl -sf http://localhost:4566/_localstack/health > /dev/null 2>&1; do echo "Waiting..."; sleep 2; done'
          echo "LocalStack is ready!"
          curl -s http://localhost:4566/_localstack/health | python -m json.tool
      
      - name: Setup AWS resources in LocalStack
        run: uv run python -m infrastructure.setup_localstack
        env:
          AWS_ENDPOINT_URL: http://localhost:4566
          AWS_ACCESS_KEY_ID: test
          AWS_SECRET_ACCESS_KEY: test
          AWS_DEFAULT_REGION: us-east-1
      
      - name: Run integration tests
        run: uv run pytest tests/ -v -m "integration"
        env:
          AWS_ENDPOINT_URL: http://localhost:4566
          AWS_ACCESS_KEY_ID: test
          AWS_SECRET_ACCESS_KEY: test
          AWS_DEFAULT_REGION: us-east-1
          GFN_API_KEY: ${{ secrets.GFN_API_KEY }}

  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"
          github-token: ${{ github.token }}
      
      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: uv sync --dev
      
      - name: Run Bandit security scan
        run: uv run bandit -r src/ -ll -x tests/
        continue-on-error: true
      
      - name: Check for secrets with TruffleHog
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: ${{ github.event.repository.default_branch }}
          head: HEAD
        continue-on-error: true

  # Optional: Data quality checks (requires API key)
  data-quality:
    name: Data Quality Checks
    runs-on: ubuntu-latest
    needs: integration-test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      
      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"
          github-token: ${{ github.token }}
      
      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: uv sync --dev
      
      - name: Run sample extraction to DuckDB
        run: |
          uv run python -m gfn_pipeline.pipeline_async --start-year 2023 --end-year 2023
        env:
          GFN_API_KEY: ${{ secrets.GFN_API_KEY }}
          DESTINATION: duckdb
        continue-on-error: true
      
      - name: Validate extracted data structure
        run: |
          uv run python -c "
          import duckdb
          import sys
          try:
              conn = duckdb.connect('gfn_duckdb.duckdb', read_only=True)
              result = conn.execute('SELECT COUNT(*) FROM gfn.footprint_data').fetchone()
              print(f'âœ“ Extracted {result[0]} records')
              if result[0] == 0:
                  print('âš  No records extracted - API key may be invalid')
                  sys.exit(0)  # Don't fail, just warn
          except Exception as e:
              print(f'âš  Could not validate: {e}')
              sys.exit(0)
          "
        continue-on-error: true

  deploy-staging:
    name: Deploy to Staging (LocalStack)
    runs-on: ubuntu-latest
    needs: [test, security-scan]
    if: github.ref == 'refs/heads/develop'
    environment: staging
    services:
      localstack:
        image: localstack/localstack:3.0
        ports:
          - 4566:4566
        env:
          SERVICES: s3,lambda,sqs,sns,events,stepfunctions,logs,iam
          DEFAULT_REGION: us-east-1
          DOCKER_HOST: unix:///var/run/docker.sock
        options: >-
          --health-cmd "curl -sf http://localhost:4566/_localstack/health"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v4
      
      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"
          github-token: ${{ github.token }}
      
      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: uv sync --dev
      
      - name: Wait for LocalStack to be ready
        run: |
          echo "Waiting for LocalStack..."
          timeout 60 bash -c 'until curl -sf http://localhost:4566/_localstack/health > /dev/null 2>&1; do echo "Waiting..."; sleep 2; done'
          echo "LocalStack is ready!"
          curl -s http://localhost:4566/_localstack/health | python -m json.tool
      
      - name: Setup AWS resources in LocalStack
        run: uv run python -m infrastructure.setup_localstack
        env:
          AWS_ENDPOINT_URL: http://localhost:4566
          AWS_ACCESS_KEY_ID: test
          AWS_SECRET_ACCESS_KEY: test
          AWS_DEFAULT_REGION: us-east-1
      
      - name: Run staging pipeline (dlt + DuckDB)
        run: |
          echo "ðŸš€ Running staging pipeline with dlt + DuckDB..."
          uv run python -m gfn_pipeline.main \
            --destination duckdb \
            --start-year 2023 \
            --end-year 2023 \
            --with-soda \
            --soda-warn-only
        env:
          AWS_ENDPOINT_URL: http://localhost:4566
          AWS_ACCESS_KEY_ID: test
          AWS_SECRET_ACCESS_KEY: test
          AWS_DEFAULT_REGION: us-east-1
          S3_BUCKET: gfn-data-lake
          GFN_API_KEY: ${{ secrets.GFN_API_KEY }}
          DESTINATION: duckdb
      
      - name: Validate staging deployment
        run: |
          echo "âœ… Validating staging deployment..."
          uv run python -c "
          import duckdb
          conn = duckdb.connect('gfn_duckdb.duckdb', read_only=True)
          
          # Check tables exist
          tables = conn.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'gfn'\").fetchall()
          print(f'Tables in gfn schema: {[t[0] for t in tables]}')
          
          # Check record counts
          for table in tables:
              count = conn.execute(f'SELECT COUNT(*) FROM gfn.{table[0]}').fetchone()[0]
              print(f'  - {table[0]}: {count} records')
          
          print('âœ… Staging deployment validated successfully!')
          "
        continue-on-error: true
      
      - name: Upload DuckDB artifact
        uses: actions/upload-artifact@v4
        with:
          name: staging-duckdb
          path: gfn_duckdb.duckdb
          retention-days: 7
        continue-on-error: true

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [test, security-scan, data-quality]
    if: github.ref == 'refs/heads/main'
    environment: production
    steps:
      - name: Check for AWS credentials
        id: check-creds
        run: |
          if [ -z "${{ secrets.AWS_ACCESS_KEY_ID }}" ]; then
            echo "has_creds=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ AWS credentials not configured - skipping deployment"
          else
            echo "has_creds=true" >> $GITHUB_OUTPUT
          fi
      
      - uses: actions/checkout@v4
        if: steps.check-creds.outputs.has_creds == 'true'
      
      - name: Configure AWS credentials
        if: steps.check-creds.outputs.has_creds == 'true'
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Install uv
        if: steps.check-creds.outputs.has_creds == 'true'
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"
          github-token: ${{ github.token }}
      
      - name: Set up Python
        if: steps.check-creds.outputs.has_creds == 'true'
        run: uv python install ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        if: steps.check-creds.outputs.has_creds == 'true'
        run: uv sync
      
      - name: Deploy Lambda functions to production
        if: steps.check-creds.outputs.has_creds == 'true'
        run: |
          echo "Deploying to production environment..."
          # Package Lambda functions
          # uv run python -m infrastructure.deploy --environment production
          echo "TODO: Add Terraform deployment commands"
          # cd infrastructure/terraform
          # terraform init
          # terraform workspace select production || terraform workspace new production
          # terraform apply -auto-approve
